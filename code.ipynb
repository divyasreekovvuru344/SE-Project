{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","\n","import os\n","print(os.listdir(\"../input\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["from tensorflow.python.keras.applications import ResNet50\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n","from tensorflow.python.keras.applications.resnet50 import preprocess_input\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n","\n","resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c4482e803aa07100f91dcc99ad518fbdbc7cf0dd","trusted":true},"outputs":[],"source":["data_generator = ImageDataGenerator(horizontal_flip=True,\n","                                   width_shift_range = 0.4,\n","                                   height_shift_range = 0.4,\n","                                   zoom_range=0.3,\n","                                   rotation_range=20,\n","                                   )\n","\n","image_size = 224\n","batch_size = 10\n","train_generator = data_generator.flow_from_directory(\n","        '../input/flowers-recognition/flowers/flowers/',\n","        target_size=(image_size, image_size),\n","        batch_size=batch_size,\n","        class_mode='categorical')\n","\n","num_classes = len(train_generator.class_indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"43d5039aaaa7781a8a907713c2533a269b952840","collapsed":true,"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n","model.add(Flatten())\n","model.add(BatchNormalization())\n","model.add(Dense(2048, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1024, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.layers[0].trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f58aab782b26fc50e880537ef026faab68a1fac7","collapsed":true,"trusted":true},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b77f98c4fd469be1c23b3994456a69421d7c615a","trusted":true},"outputs":[],"source":["count = sum([len(files) for r, d, files in os.walk(\"../input/flowers-recognition/flowers/flowers/\")])\n","\n","model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=int(count/batch_size) + 1,\n","        epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e61eb4e2eafd37bb33d1fc8350571b674b0ad27b","collapsed":true,"trusted":true},"outputs":[],"source":["from IPython.display import Image, display\n","\n","import os, random\n","img_locations = []\n","for d in os.listdir(\"../input/flowers-recognition/flowers/flowers/\"):\n","    directory = \"../input/flowers-recognition/flowers/flowers/\" + d\n","    sample = [directory + '/' + s for s in random.sample(\n","        os.listdir(directory), int(random.random()*10))]\n","    img_locations += sample"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0248d5916e7b0014effd3289f566c06f992a3523","collapsed":true,"trusted":true},"outputs":[],"source":["def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n","    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n","    img_array = np.array([img_to_array(img) for img in imgs])\n","    return preprocess_input(img_array)\n","\n","random.shuffle(img_locations)\n","imgs = read_and_prep_images(img_locations)\n","predictions = model.predict_classes(imgs)\n","classes = dict((v,k) for k,v in train_generator.class_indices.items())\n","\n","for img, prediction in zip(img_locations, predictions):\n","    display(Image(img))\n","    print(classes[prediction])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d092e6be05347b772149b813c285cfff5f78a8b0","collapsed":true,"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":1}
